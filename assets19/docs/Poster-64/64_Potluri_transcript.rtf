{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 A multi-modal approach for blind and visually impaired developers to edit webpage designs by Venkatesh Potluri, Liang He, Christine Chen, Jon E. Froehlich and Jennifer Mankoff from Paul G. Allen School of Computer Science and Engineering, University of Washington\
Content creators who are blind and visually impaired are actively creating interfaces meant for visual consumption. While these interfaces are expected to have good visual design, the necessary tools and information to build visually pleasing interfaces are not accessible to developers who are blind and visually impaired \
\
To address this gap, we propose a multi-modal approach, using an Integrated Development Environment and touch gestures to enable BVI developers to edit web page designs without breaking visual aesthetics. We demonstrate our approach through a multi-modal system and present preliminary findings from a pilot. Future work will enhance validation through formal verification and machine learning techniques, investigate learnability and discoverability of our current gesture set and explore new interaction techniques.\
\
The picture shows a user interacting with the webpage representation on the accessible canvas, an iPad. The code editor (with the underlying CSS) is displayed on a laptop. \
 \
The system consists of three modules: the accessible canvas on the left, the code editor on the right, and the controller in the middle. \
The poster has logos of the  Paul G. Allen School of Computer Science and Engineering, Design Use Build, Makeability Lab and Make4All}