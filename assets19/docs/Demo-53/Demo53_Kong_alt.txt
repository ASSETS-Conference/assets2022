Figure 1: The system repeatedly run three major steps: detecting current state of interface from phone camera, updating position in the action sequence, and providing AR visual guidance and voice feedback. 
Figure 2: Screenshots of example visual guidance to complete the task of copying a document on a printer. In the first screenshot, the app displays a circle around the OK button to press with text display on the screen saying “Now press the OK button”; in the second screenshot, the app displays an arrow on the opening side of the top cover of the printer, with text display on the screen saying “Wonderful! Now open top cover of printer”; in the third screenshot, the app displays a 3D plane with text on the side facing the scanning area, indicating the document to be copied, with text display on the screen saying “Nice! Now place document to copy”.
Figure 3: Diagram of example action sequence to complete the task of copying a document on a printer. The states go from “Home”, to “Copy Info”, then “Cover Opened”, and “Document placed”, then “Copying”, and “Copy Complete”, to finally “Done”. The actions that trigger the state transitions are, “Press OK”, “Open Top Cover”, “Place Document”, “Press Start”, “Press Home”.