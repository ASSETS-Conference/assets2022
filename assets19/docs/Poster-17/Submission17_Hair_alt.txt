Figure 1
Two screenshots from the Apraxia World game. One shows the monkey avatar in a jungle level and the other shows a speech exercise popup prompting the player to say "Jar" by displaying the word and a picture.

Figure 2
Diagram for the template matching process. In the first part, the feature vector is created by trimming leading and trailing silence from a recording, applying pre-emphasis, extracting MFCC features, and applying cepstral mean normalization. In the second part, a test feature vector is time aligned with a template feature vector and the frame-wise distance is computed between the two.

Figure 3
Boxplots for word-level accuracy of the four speech recognition methods. PocketSphinx with the default acoustic model has the worst accuracy, followed by MLLR-adapted models, then template matching, and MAP-adapted models have the best accuracy.

Table 1
Shows average word recognition accuracy for each speech recognition method per speaker. MAP-adapted models and template matching work best, although which of the two works better is speaker-dependent.